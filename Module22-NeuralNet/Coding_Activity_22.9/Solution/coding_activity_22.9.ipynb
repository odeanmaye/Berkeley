{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b3b2d417bfed0767",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 22.9: End to End Classification with `keras`\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 20**\n",
    "\n",
    "This activity focuses on using a dataset that contains a mix of feature types to build a binary classification model.  You will use familiar scikit-learn preprocessing operations to handle categorical features, and use the transformed data together with a `keras` model.  After building a familiar model, further examples are shown using regularization strategies for neural networks.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a02f3a1d08dfb98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "The dataset contains information gathered from the United States Census about whether or not the individual earned over \\$50,000 per year. ([more info here](https://archive.ics.uci.edu/ml/datasets/Adult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('income', axis = 1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-debcec427ec26222",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Preparing the Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the `make_column_transformer` to transform the feature array as `X_train_num` and `X_test_num` using the `OneHotEncoder` with `drop = if_binary` and existing numeric data should be scaled using `StandardScaler`.  \n",
    "\n",
    "For the target, assign the values of `y_train_num` and `y_test_num` as a binary array where 1 represents observations earning over \\$50,000 per year, and 0 less.  Note that as long as you have a purely numeric array, the `keras` model will accept this as input.  While you can use a sparse array, here you are to transform the sparse array to a dense array with the `.toarray()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes('object').columns[:-1] #categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique() #unique values of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True) #baseline for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bcd0e55ebe7bcaa1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "transformer = ''\n",
    "X_train_num = ''\n",
    "X_test_num = ''\n",
    "\n",
    "y_train_num = ''\n",
    "y_test_num = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "transformer = make_column_transformer((OneHotEncoder(drop = 'if_binary'), ['workclass', 'education', 'marital.status', 'occupation',\n",
    "       'relationship', 'race', 'sex', 'native.country']),\n",
    "                                     remainder = StandardScaler())\n",
    "X_train_num = transformer.fit_transform(X_train).toarray()\n",
    "X_test_num = transformer.transform(X_test).toarray()\n",
    "\n",
    "y_train_num = np.where(y_train == '<=50K', 0, 1)\n",
    "y_test_num = np.where(y_test == '<=50K', 0, 1)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(np.unique(y_train_num))\n",
    "print(type(X_train_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-076d153da5eb6f6e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "transformer_ = make_column_transformer((OneHotEncoder(drop = 'if_binary'), ['workclass', 'education', 'marital.status', 'occupation',\n",
    "       'relationship', 'race', 'sex', 'native.country']),\n",
    "                                     remainder = StandardScaler())\n",
    "X_train_num_ = transformer_.fit_transform(X_train).toarray()\n",
    "X_test_num_ = transformer_.transform(X_test).toarray()\n",
    "\n",
    "y_train_num_ = np.where(y_train == '<=50K', 0, 1)\n",
    "y_test_num_ = np.where(y_test == '<=50K', 0, 1)\n",
    "#\n",
    "#\n",
    "#\n",
    "np.testing.assert_array_equal(X_train_num, X_train_num_)\n",
    "np.testing.assert_array_equal(y_train_num, y_train_num_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1481dab390d2772c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Building the model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, use `keras` to build a model using a single hidden layer using 50 units and a single output layer, naming the model `model1`.  Fit the model and work to build a model using 10 training epochs.  Note the accuracy on the validation set.\n",
    "\n",
    "NOTE: This question is computationally expensive and may take a minute or two to complete calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-288e9367eed17065",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "model1 = ''\n",
    "history1 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(50, activation = 'relu'))\n",
    "model1.add(Dense(1, activation = 'sigmoid'))\n",
    "model1.compile(loss = 'bce', metrics = ['acc'])\n",
    "history1 = model1.fit(X_train_num, y_train_num, validation_data = (X_test_num, y_test_num),\n",
    "                     epochs = 10, verbose = 0)\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(history1.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4853b5f2c733abc7",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "model1_ = Sequential()\n",
    "model1_.add(Dense(50, activation = 'relu'))\n",
    "model1_.add(Dense(1, activation = 'sigmoid'))\n",
    "model1_.compile(loss = 'bce', metrics = ['acc'])\n",
    "history1_ = model1_.fit(X_train_num, y_train_num, validation_data = (X_test_num, y_test_num),\n",
    "                     epochs = 10, verbose = 0)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(history1) == type(history1_)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f47a122152b4c88d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exploring Regularization\n",
    "\n",
    "Below, the questions introduce the notion of regularization in your `keras` models.  The following questions are not graded, but are meant to offer exploratory introduction to using regularization in the neural network.  This may or may not improve our model for income -- but they are important components of some advanced architectures including those coming in the next module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04c00ba81b855d55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Regularization in the Network\n",
    "\n",
    "Similar to what we have seen in early models, there are some options for regularization in your neural network.  Below, `model2` uses `kernel_regularizer = 'l1'` to apply L1 regularization to the hidden layer.  \n",
    "\n",
    "Explore other options built in to the `Dense` layer for regularization and see if applying either `l1` or `l2` regularization to the kernel and bias elements of the hidden layer.  \n",
    "\n",
    "Assign your new model as `model2` below, and the fit information as `history2` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(50, activation = 'relu', kernel_regularizer = 'l1'))\n",
    "\n",
    "model2.add(Dense(1, activation = 'sigmoid'))\n",
    "model2.compile(loss = 'bce', metrics = ['acc'])\n",
    "history2 = model2.fit(X_train_num, y_train_num, validation_data=(X_test_num, y_test_num),\n",
    "           epochs = 10, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28c2788d980f8547",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Dropout\n",
    "\n",
    "An alternative option for regularization is the `Dropout` layer.  This layer randomly \"drops out\" nodes in a given layer.  From the `keras` documentation:\n",
    "\n",
    "```\n",
    "The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.\n",
    "```\n",
    "\n",
    "To use this, the code below creates a model where 20% of the nodes in the hidden layer will be randomly dropped in each training epoch.  Experiment with this model and incorporate other regularization strategies from above to see if you can improve the performance of predictions on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(50, activation = 'relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(1, activation = 'sigmoid'))\n",
    "model3.compile(loss = 'bce', metrics = ['acc'])\n",
    "history = model3.fit(X_train_num, y_train_num, validation_data=(X_test_num, y_test_num),\n",
    "           epochs = 10, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3e7d51b8df6b4f77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Early Stopping\n",
    "\n",
    "A third option for regularization is *Early Stopping*.  Here, you can set the model to stop training when overfitting begins.  Overfitting can be defined as the difference between training and validation data during each epoch of training.\n",
    "\n",
    "To use this in `keras` you use a *callback*.  This is an object that is created and passed as an argument during the fitting of the model.  Below, the code demonstrates the use of the `EarlyStopping` callback from `keras`. Use this to explore alternative settings with both `Dropout` and kernel regularization to see if you can improve the performance of the network.\n",
    "\n",
    "Plot the training and validation data to explore how early stopping truncated the training when overfitting begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopper = EarlyStopping(patience = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(50, activation = 'relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(1, activation = 'sigmoid'))\n",
    "model4.compile(loss = 'bce', metrics = ['acc'])\n",
    "history4 = model4.fit(X_train_num, y_train_num, validation_data=(X_test_num, y_test_num),\n",
    "           epochs = 1, verbose = 0,\n",
    "                    callbacks = stopper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
