{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1af27d3e65f74335",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 23.4: Fine Tuning a Pre-trained Network\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 30**\n",
    "\n",
    "In addition to the use of a pre-trained network to extract features from a different dataset, the weights can be adjusted or **fine-tuned** as a last step to squeeze additional performance from the network.  To do so, you will again use the `EfficientNetV2B0` network on the `cifar10` data from `keras`.  This time you are encouraged to use the functional API syntax to construct your network.  \n",
    "\n",
    "For a second example, consult the `keras` documentation example [here](https://keras.io/guides/transfer_learning/). \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "\n",
    "Run the code cell below to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 16:58:50.322351: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-21 16:58:50.322409: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "sub_indices = pd.DataFrame(y_train, columns= [\"labels\"]).groupby('labels', group_keys=False).apply(lambda x: x.sample(frac=0.3, random_state=123)).index\n",
    "X_train = X_train[sub_indices]\n",
    "y_train = y_train[sub_indices]\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8d37aca8ee95d87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Training the Network to Convergence\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In the code cell below, use the function `EfficientNetV2B0` with the appropriate input shape and the argument `include_top` equal to `False` to create the model you will be using for this activity. Assign your result to `base_model`.\n",
    "\n",
    "Use the function `Input()` with argument `shape` equal to `(32, 32, 3)` and assign your result to the variable `inputs`.\n",
    "\n",
    "Use `base_model` with argument equal to `inputs` and assign your result to the variable `x`.\n",
    "\n",
    "Use the function `Flatten` to flatten `x`. The pseudocode to complete this step is given below:\n",
    "\n",
    "```Python\n",
    "x = Flatten()(...)\n",
    "```\n",
    "\n",
    "Pass `x` through a `Dense` layer with 10 hidden nodes and `activation` equal to `relu` and assign the result to the variable `output`. The pseudocode to complete this step is given below:\n",
    "\n",
    "```Python\n",
    "output = Dense(..., activation = ...)(...)\n",
    "```\n",
    "\n",
    "Use the code `base_model.trainable = False` to ensure that your weights are not trainable.\n",
    "\n",
    "Use the function `Model()` with argument `inputs` and `output` to define your model. Assign the result to the variable `model`.\n",
    "\n",
    "Compile `model` using `categorical_crossentropy` as your `loss` and `accuracy` as your `metric`.\n",
    "\n",
    "Use the `fit()` function on `model` to fit the  training data `X_train` and `Y_train`. Set the argument `validation_data` equal to `(X_test, Y_test)` and the argument `epochs` equal to 1.  Assign the result to the variable `bottom_model` below. \n",
    "\n",
    "NOTE: This question is computationally expensive, so please be patient with the processing. It may take a few minutes based on your computing power. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e92e20d0c85d3026",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 16:59:03.831934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-21 16:59:03.831995: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-21 16:59:03.833111: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (stronggarbo-aztecimmune): /proc/driver/nvidia/version does not exist\n",
      "2022-11-21 16:59:03.834818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 50s 88ms/step - loss: 1.5093 - accuracy: 0.4675 - val_loss: 1.2373 - val_accuracy: 0.5638\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 1.2467 - accuracy: 0.5626 - val_loss: 1.2401 - val_accuracy: 0.5615\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 34s 72ms/step - loss: 1.1757 - accuracy: 0.5861 - val_loss: 1.1614 - val_accuracy: 0.5910\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 1.1217 - accuracy: 0.6063 - val_loss: 1.2619 - val_accuracy: 0.5663\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 34s 73ms/step - loss: 1.0887 - accuracy: 0.6166 - val_loss: 1.1805 - val_accuracy: 0.5848\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 1, 1, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               128100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,048,422\n",
      "Trainable params: 129,110\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "base_model = ''\n",
    "inputs = ''\n",
    "x = ''\n",
    "x = ''\n",
    "x = ''\n",
    "output = ''\n",
    "model = ''\n",
    "#be sure to compile\n",
    "\n",
    "bottom_model = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "base_model = EfficientNetV2B0(input_shape = (32, 32, 3), include_top=False)\n",
    "inputs = Input(shape = (32, 32, 3))\n",
    "x = base_model(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(10, activation = 'relu')(x)\n",
    "output = Dense(10, activation = 'sigmoid')(x)\n",
    "base_model.trainable = False\n",
    "model = Model(inputs, output)\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "bottom_model = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), \n",
    "                    epochs = 1)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c7a974852163092b",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 52s 90ms/step - loss: 1.5343 - accuracy: 0.4644 - val_loss: 1.2853 - val_accuracy: 0.5555\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 1.2563 - accuracy: 0.5579 - val_loss: 1.2166 - val_accuracy: 0.5710\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 1.1789 - accuracy: 0.5853 - val_loss: 1.1935 - val_accuracy: 0.5897\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 35s 74ms/step - loss: 1.1236 - accuracy: 0.6075 - val_loss: 1.1563 - val_accuracy: 0.5891\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 34s 73ms/step - loss: 1.0934 - accuracy: 0.6144 - val_loss: 1.2450 - val_accuracy: 0.5783\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 1, 1, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               128100    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,048,422\n",
      "Trainable params: 129,110\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "base_model_ = EfficientNetV2B0(input_shape = (32, 32, 3), include_top=False)\n",
    "inputs_ = Input(shape = (32, 32, 3))\n",
    "x_ = base_model(inputs_)\n",
    "x_ = Flatten()(x_)\n",
    "x_ = Dense(100, activation = 'relu')(x_)\n",
    "output_ = Dense(10, activation = 'sigmoid')(x_)\n",
    "model_ = Model(inputs_, output_)\n",
    "model_.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#\n",
    "#\n",
    "#\n",
    "assert type(base_model) == type(base_model_)\n",
    "### END HIDDEN TESTS\n",
    "print(model_.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-72d9644d3c68011b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Setting to Trainable\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In the code cell below, use the code `base_model.trainable = True` to ensure that your weights are now trainable.\n",
    "\n",
    "\n",
    "Set the final five layers to trainable in the `base_model` as demonstrated in the lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable #are the base model weights set to trainable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-17e4f0a4de6dc3b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: False\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n",
      "Layer is trainable: True\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "base_model.trainable = True\n",
    "for layer in '':\n",
    "    #make trainable\n",
    "    pass\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "for i, layer in enumerate(base_model.layers[-10:]):\n",
    "    print(f'Layer is trainable: {layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-279935493600bece",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "base_model_.trainable = True\n",
    "for layer in base_model_.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "#\n",
    "#\n",
    "#\n",
    "for i, layer in enumerate(base_model.layers[-5:]):\n",
    "    assert layer.trainable == True\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0307a936396eedc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Refitting the network\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "In the code cell below, use the function `compile` on `model` using `categorical_crossentropy` as your `loss` and `accuracy` as your `metric`.\n",
    "\n",
    "Next, use the `fit()` function on `model` to fit the  training data `X_train` and `Y_train`. Set the argument `validation_data` equal to `(X_test, Y_test)` and the argument `epochs` equal to 1.  Assign the result to the variable `fine_tuned_history` below. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-75f43fbafe9c0840",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 56s 90ms/step - loss: 1.6604 - accuracy: 0.5090 - val_loss: 1.2255 - val_accuracy: 0.5940\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 40s 85ms/step - loss: 1.0498 - accuracy: 0.6427 - val_loss: 1.1942 - val_accuracy: 0.6157\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 39s 82ms/step - loss: 0.9001 - accuracy: 0.6948 - val_loss: 1.1988 - val_accuracy: 0.6255\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 44s 95ms/step - loss: 0.7925 - accuracy: 0.7295 - val_loss: 1.3052 - val_accuracy: 0.6044\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 36s 77ms/step - loss: 0.7065 - accuracy: 0.7631 - val_loss: 1.3319 - val_accuracy: 0.6179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7630666494369507"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "fine_tuned_history = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "fine_tuned_history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 1)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "fine_tuned_history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c60ddea5358927c2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 55s 94ms/step - loss: 0.9569 - accuracy: 0.6874 - val_loss: 1.3558 - val_accuracy: 0.6133\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 35s 76ms/step - loss: 0.7281 - accuracy: 0.7573 - val_loss: 1.3930 - val_accuracy: 0.6100\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 35s 74ms/step - loss: 0.6363 - accuracy: 0.7869 - val_loss: 1.4276 - val_accuracy: 0.6243\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 36s 77ms/step - loss: 0.5828 - accuracy: 0.8080 - val_loss: 1.5683 - val_accuracy: 0.6173\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 34s 73ms/step - loss: 0.5433 - accuracy: 0.8201 - val_loss: 1.5925 - val_accuracy: 0.6181\n"
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "model_.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#\n",
    "#\n",
    "#\n",
    "#assert len(fine_tuned_history.history['accuracy']) == len(fine_tuned_history_.history['accuracy'])\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
