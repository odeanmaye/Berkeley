{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1bc26ee627d5273",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 13.7: Multi-Class Logistic Regression\n",
    "\n",
    "**Expected Time = 90 minutes**\n",
    "\n",
    "**Total Points = 60**\n",
    "\n",
    "This activity focuses on implementing `LogisticRegression` estimator using three approaches for multi class classification.  Two of these, one vs. rest and multinomial, are available using the estimator directly.  The third example, one vs. one, is implemented from the scikit-learn `multiclass` module.  Most important is that you can consider each of these models as options when building classification models and that you select the best depending on your identified metric.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n",
    "- [Problem 5](#Problem-5)\n",
    "- [Problem 6](#Problem-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b34f8d20a529570",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "Below, the `penguins` data is loaded and the target feature for all classes is converted to a numeric value.  Thus, we have three classes where 0, 1, and 2 represent Adelie, Chinstrap, and Gentoo respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Adelie', 'Chinstrap', 'Gentoo'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "penguins = sns.load_dataset('penguins').dropna()\n",
    "X = penguins.drop(['species', 'island', 'sex'], axis = 1)\n",
    "y = penguins.species\n",
    "y_num = pd.factorize(y)[0]\n",
    "categories = pd.factorize(y)[1]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "0            39.1           18.7              181.0       3750.0\n",
       "1            39.5           17.4              186.0       3800.0\n",
       "2            40.3           18.0              195.0       3250.0\n",
       "4            36.7           19.3              193.0       3450.0\n",
       "5            39.3           20.6              190.0       3650.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=518)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b64d32b13d201e6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### One vs. Rest Classification\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To begin, use the `LogisticRegression` estimator with the argument `multi_class = 'ovr'`, `max_iter=1000`, and `random_state = 42` to instantiate a model named `ovr_lgr`. The use itto fit the model on the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd11c6c0e63c7d0e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='ovr', random_state=42)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "ovr_lgr = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ovr_lgr = LogisticRegression(multi_class='ovr', max_iter=1000, random_state=42).fit(X_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "ovr_lgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-310233923fdbe4e5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Examining the Probabilities\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Use the `predict_proba` function to examine the predicted probabilities on the testing data.  Assign these to `ovr_probs` as an array below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-566e611d496dd3fc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(adelie)</th>\n",
       "      <th>p(gentoo)</th>\n",
       "      <th>p(chinstrap)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.997758e-01</td>\n",
       "      <td>3.366719e-05</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.112815e-04</td>\n",
       "      <td>2.247698e-04</td>\n",
       "      <td>0.999564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.633864e-05</td>\n",
       "      <td>1.776670e-07</td>\n",
       "      <td>0.999933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.564999e-07</td>\n",
       "      <td>7.146215e-04</td>\n",
       "      <td>0.999285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.835565e-01</td>\n",
       "      <td>1.312682e-09</td>\n",
       "      <td>0.016444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      p(adelie)     p(gentoo)  p(chinstrap)\n",
       "0  9.997758e-01  3.366719e-05      0.000191\n",
       "1  2.112815e-04  2.247698e-04      0.999564\n",
       "2  6.633864e-05  1.776670e-07      0.999933\n",
       "3  2.564999e-07  7.146215e-04      0.999285\n",
       "4  9.835565e-01  1.312682e-09      0.016444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "ovr_probs = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ovr_probs = ovr_lgr.predict_proba(X_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "pd.DataFrame(ovr_probs, columns = ['p(adelie)', 'p(gentoo)', 'p(chinstrap)']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-484717eb2739b6b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Trying multinomial\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now, instatiate a `LogisticRegression` estimator with `max_iter=10000`, `multi_class = 'multinomial'` and `random_state = 42`.  Fit the model on the training data as `multi_lgr` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27b62c19a3e13379",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, multi_class='multinomial', random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "multi_lgr = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "multi_lgr = LogisticRegression(max_iter=10000, multi_class='multinomial', random_state=42).fit(X_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "multi_lgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1cd6899727717623",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Examining the Probabilities\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Again, use the `predict_proba` function to examine the probabilities from the multinomial estimator above on the test data.  Assign them as an array to `multi_probs` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76ecf062d62d7ac5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(adelie)</th>\n",
       "      <th>p(gentoo)</th>\n",
       "      <th>p(chinstrap)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999990</td>\n",
       "      <td>3.395344e-06</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>4.414225e-04</td>\n",
       "      <td>0.999150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>4.059417e-07</td>\n",
       "      <td>0.999969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.213692e-04</td>\n",
       "      <td>0.999577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999912</td>\n",
       "      <td>3.187090e-10</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p(adelie)     p(gentoo)  p(chinstrap)\n",
       "0   0.999990  3.395344e-06      0.000007\n",
       "1   0.000409  4.414225e-04      0.999150\n",
       "2   0.000030  4.059417e-07      0.999969\n",
       "3   0.000002  4.213692e-04      0.999577\n",
       "4   0.999912  3.187090e-10      0.000088"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "multi_probs = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "multi_probs = multi_lgr.predict_proba(X_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "pd.DataFrame(multi_probs, columns = ['p(adelie)', 'p(gentoo)', 'p(chinstrap)']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-829714790aa8038d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### One vs. One Classifier\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Similar in thinking to the one vs. rest approach, the one vs. one approach pairs every combination of the target class and builds a logistic model on this binary problem.  This means that for three classes you would have 6 different logistic regressors.  \n",
    "\n",
    "The LogisticRegression estimator does not have this as a default. However, Scikit-learn implements this approach through the `OneVsOneClassifier` that accepts a classification estimator. \n",
    "\n",
    "Below, instantiate a `OneVsOneClassifier` estimator with a `LogisticRegression`  estimator with parsmeter `max_iter=1000` and `random_state = 42`as `ovo_clf`. Fit this to the training data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7f080ac18ecc63d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsOneClassifier(estimator=LogisticRegression(max_iter=1000, random_state=42))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "ovo_clf = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ovo_clf = OneVsOneClassifier(LogisticRegression(max_iter=1000, random_state = 42)).fit(X_train, y_train)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "ovo_clf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d8c60d80a8f7139",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Comparing Performance\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Create a DataFrame that contains the scores on testing data in terms of accuracy.  Assign to `eval_df` below.  Which classifier performed best in terms of accuracy?  Assign your answer as a string -- `ovr`, `multi`, or `ovo` -- below to `best_acc`. \n",
    "\n",
    "| estimator | accuracy | \n",
    "| ------ | ------ |\n",
    "| ovo | - |\n",
    "| multi | - |\n",
    "| ovo | - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-21c1289df7ce1c76",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovr\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "\n",
    "best_acc = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "ovr_acc = accuracy_score(y_test, ovr_lgr.predict(X_test))\n",
    "multi_acc = accuracy_score(y_test, multi_lgr.predict(X_test))\n",
    "ovo_acc = accuracy_score(y_test, ovo_clf.predict(X_test))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'estimator': ['ovr', 'multi', 'ovo'], \n",
    "        'accuracy': [ovr_acc, multi_acc, ovo_acc]\n",
    "    }\n",
    ")\n",
    "\n",
    "best_acc = df.loc[df['accuracy'].idxmax()]['estimator']\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6c7b9795de3ecce",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Hopefully this activity increased your facility with the `LogisticRegression` estimator and how it can be used in a multi-class setting.  Of course, these options are things you may consider in a grid search rather than fitting each on their own, however the One vs. One will have to implemented as its own object.  Further, many of the fitting procedures should raise warnings.  As seen before, there is regularization behind the scenes so scaling the data should happen prior to fitting.  Further, you may need to give the estimator more time for the gradient descent to converge, which you can control with the `max_iter` argument."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
