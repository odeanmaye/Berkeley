{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfb3b6e3696eff65",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Codio Activity 15.9: Stochastic Gradient Descent\n",
    "\n",
    "**Expected Time = 30 minutes**\n",
    "\n",
    "**Total Points = 20**\n",
    "\n",
    "This activity explores the use of the `SGDRegressor` from scikitlearn.  While there is not a standard gradient descent estimator, the more efficient example of stochastic gradient descent is available.  You will use the earlier credit dataset to explore its use and learn an important lesson about scaling your data with gradient descent methods. \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('../../data/Credit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit[['Income', 'Limit']]\n",
    "y = credit['Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c65193ba8d1cc68",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Fitting a basic Linear Regression model\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "To begin, use the `LinearRegression` with all default parameters to build a model on the training data and evaluate this on the testing data.  Assign the estimator to `lr` below and training and testing error to `train_mse` and `test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-070c21d90d3625e3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "lr = ''\n",
    "train_mse = ''\n",
    "test_mse = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "train_mse = mean_squared_error(y_train, lr.predict(X_train))\n",
    "test_mse = mean_squared_error(y_test, lr.predict(X_test))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(train_mse)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8d7c563dc380a23b",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "lr_ = LinearRegression().fit(X_train, y_train)\n",
    "train_mse_ = mean_squared_error(y_train, lr_.predict(X_train))\n",
    "test_mse_ = mean_squared_error(y_test, lr_.predict(X_test))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert train_mse == train_mse_\n",
    "assert test_mse == test_mse_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7f119dc798009c7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Fitting a basic SGD model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "To begin, use the `SGDRegressor` with all default parameters **except** `random_state = 42` to build a model on the training data and evaluate this on the testing data.  Assign the estimator to `sgd_defaults` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76a36ca97a2b71c5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_186/118067456.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### BEGIN SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msgd_defaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd_defaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd_defaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "sgd_defaults = ''\n",
    "    \n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "sgd_defaults = SGDRegressor(random_state=42).fit(X_train, y_train)\n",
    "train_mse = mean_squared_error(y_train, sgd_defaults.predict(X_train))\n",
    "test_mse = mean_squared_error(y_test, sgd_defaults.predict(X_test))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(sgd_defaults)\n",
    "print(train_mse)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-226f6233b2f17922",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "sgd_defaults_ = SGDRegressor(random_state=42).fit(X_train, y_train)\n",
    "train_mse_ = mean_squared_error(y_train, sgd_defaults_.predict(X_train))\n",
    "test_mse_ = mean_squared_error(y_test, sgd_defaults_.predict(X_test))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert round(train_mse, 0) == round(train_mse_, 0)\n",
    "assert test_mse == test_mse_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ffede5ecd7c59430",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Scaling the Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "An important message in gradient descent methods is that scaling the data and using regularization helps to constrain the solution path.  You should be able to see the effect of providing the `SGDRegressor` scaled data below.  Fit a second model using the scaled data below and compare the mean squared error to that of the standard `LinearRegression` estimator.  Assign the estimator with `random_state` to `sgd_scaled` below and the train and test mean squared error to `train_mse` and `test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_tr_scaled = scaler.fit_transform(X_train)\n",
    "X_ts_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a791ed8b60cf0a08",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "sgd_scaled = ''\n",
    "    \n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "sgd_scaled = SGDRegressor(random_state = 42).fit(X_tr_scaled, y_train)\n",
    "train_mse = mean_squared_error(y_train, sgd_scaled.predict(X_tr_scaled))\n",
    "test_mse = mean_squared_error(y_test, sgd_scaled.predict(X_ts_scaled))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(sgd_scaled)\n",
    "print(train_mse)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-72bfc7f7cfea35b2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "sgd_scaled_ = SGDRegressor(random_state=42).fit(X_tr_scaled, y_train)\n",
    "train_mse_ = mean_squared_error(y_train, sgd_scaled_.predict(X_tr_scaled))\n",
    "test_mse_ = mean_squared_error(y_test, sgd_scaled_.predict(X_ts_scaled))\n",
    "#\n",
    "#\n",
    "#\n",
    "assert round(train_mse, 0) == round(train_mse_, 0)\n",
    "assert test_mse == test_mse_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can return to your earlier examples and see if scaling your data made any differences in the gradient descent convergence, this is important to all models using a gradient descent method and you will see this again with neural networks."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
