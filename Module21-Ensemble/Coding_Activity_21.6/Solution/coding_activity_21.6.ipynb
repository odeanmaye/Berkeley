{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d164420705a4fece",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Adaboost\n",
    "\n",
    "This activity focuses on using the `AdaBoostClassifier` and the performance resulting from changing the base classifier that is used.  As discussed in the lectures, adaptive boosting is a successive reweighting of data using a set number of estimators.  These weighted estimators are what form the ensemble, and the predictions are a result of a weighted combination of the estimators.  \n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fetal.zip', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('fetal_health', axis = 1).values\n",
    "y = df['fetal_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6037217b547e73a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### `AdaBoostClassifier`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "What is the default estimator in the `AdaBoostClassifier`?  Instantiate the default estimator with the correct hyperparameters to `ans1` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-610a6433eeb011fa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "ans1 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "ans1 = DecisionTreeClassifier(max_depth=1)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-254a544f694d9ceb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans1_ = DecisionTreeClassifier(max_depth=1)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans1.max_depth == ans1_.max_depth\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9374e15cda778d0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Fitting the Ensemble\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Below, use the `AdaBoostClassifier` to fit the data.  Use all default settings and and assign the accuracy of the model on the test data to `model_1_acc` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92ed88043191a639",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.881578947368421\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "model_1 = ''\n",
    "model_1_acc = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "model_1 = AdaBoostClassifier().fit(X_train, y_train)\n",
    "model_1_acc = model_1.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(model_1_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a4e2adfd28e5c9fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "model_1_ = AdaBoostClassifier().fit(X_train, y_train)\n",
    "model_1_acc_ = model_1_.score(X_test, y_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert model_1_acc_ == model_1_acc\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-905335749b0f9e64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Grid Searching the Ensemble\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "As the documentation states [here](https://scikit-learn.org/stable/modules/ensemble.html#usage), the main parameters to search are the number of estimators and the complexity of the base estimator.  Create a parameter grid that considers the following parameters:\n",
    "\n",
    "- *number of estimators*: 100, 200\n",
    "- *max_depths*: 1, 2, 3\n",
    "\n",
    "as `params` below.  Use this with the `AdaBoostClassifier` to grid search named `tree_grid` on the train data.  Assign the score on the test data as `grid_acc`.  Be sure to set the `random_state = 42` in your `AdaBoostClassifier`.\n",
    "\n",
    "**NOTE:** This is computaitonally expensive. It may take up to two minutes for the answer check (print(grid_acc) ) results to appear. It is also advised that you do NOT run the blank cell underneath (the grading cell) until you see the results from your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0510fdbbf90c3779",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "params = ''\n",
    "tree_grid = ''\n",
    "grid_acc = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "params = {'n_estimators': [100, 200],\n",
    "         'base_estimator__max_depth': [1, 2, 3]}\n",
    "tree_grid = GridSearchCV(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), random_state = 42), \n",
    "                         param_grid=params).fit(X_train, y_train)\n",
    "grid_acc = tree_grid.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(grid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2c2d4e716fcfe852",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "params_ = {'n_estimators': [100, 200],\n",
    "         'base_estimator__max_depth': [1, 2, 3]}\n",
    "tree_grid_ = GridSearchCV(AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), random_state=42), \n",
    "                         param_grid=params_).fit(X_train, y_train)\n",
    "grid_acc_ = tree_grid_.score(X_test, y_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert grid_acc == grid_acc_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8aa3fa345d098088",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### A Different Base Estimator\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Consider using a different base estimator such as `LogisticRegression` estimator.  Explore the neighbors parameters with \n",
    "\n",
    "- `C = [.001, 0.01, 0.1, 1.0, 10.0]`\n",
    "\n",
    "Create a `Pipeline` that scales the data first and then implements an `AdaBoostClassifier` with `random_state = 42` and a Logistic Regression model.  Grid search the pipeline with a grid and assign the score on the test data to `score2`. \n",
    "\n",
    "**Note:** Again, this one is computationally expensive. Be patient with the results, and do NOT run the blank cell underneath (the grading cell) until you see the results from your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bbf690915a58f45",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "score2 = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "params = {'mod__base_estimator__C': [.001, 0.01, 0.1, 1.0, 10.0]}\n",
    "p = Pipeline([('scale', StandardScaler()),\n",
    "             ('mod', AdaBoostClassifier(base_estimator = LogisticRegression(), \n",
    "                                       random_state = 42))\n",
    "             ])\n",
    "g = GridSearchCV(p,\n",
    "                param_grid=params)\n",
    "g.fit(X_train, y_train)\n",
    "score2 = g.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-84b60d9b9e7df6eb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "params_ = {'mod__base_estimator__C': [.001, 0.01, 0.1, 1.0, 10.0]}\n",
    "p_ = Pipeline([('scale', StandardScaler()),\n",
    "             ('mod', AdaBoostClassifier(base_estimator = LogisticRegression(), \n",
    "                                       random_state = 42))\n",
    "             ])\n",
    "g_ = GridSearchCV(p_,\n",
    "                param_grid=params_)\n",
    "g_.fit(X_train, y_train)\n",
    "score2_ = g_.score(X_test, y_test)\n",
    "#\n",
    "#\n",
    "#\n",
    "assert score2 == score2_\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db5a64b691d49358",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Evaluating the models\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Which model performed the best on the test data?\n",
    "\n",
    "- `a`: Base `AdaBoostClassifier`\n",
    "- `b`: Grid Searched Tree Model\n",
    "- `c`: Grid Searched Logistic Model\n",
    "- `d`: None of the above\n",
    "\n",
    "Assign your answer as a string to `ans5` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12e99140e358ffcc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "ans5 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "ans5 = 'b'\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7ee93976c0a78160",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "ans5_ = 'b'\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "assert ans5 == ans5_\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
