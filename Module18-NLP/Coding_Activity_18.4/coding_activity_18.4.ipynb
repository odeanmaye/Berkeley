{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dc73b03700d9f3ad5b79c26cd98f607",
     "grade": false,
     "grade_id": "cell-b11254d1a270988e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Codio Activity 18.4: Bag of Words: Count Vectorization\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 25**\n",
    "\n",
    "In this activity you will use the Scikit-Learn vectorization tool `CountVectorizer` to create a bag of words representation of text in a DataFrame.  You will explore how different parameter settings affect the performance of a `LogisticRegression` estimator on a binary classification problem.\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7669cd343f2afc73556e2fbb15b69be2",
     "grade": false,
     "grade_id": "cell-580b2c525505e59a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "The cell below uses the \"sad\" and \"happy\" sentiments datasets from Kaggle to form the target of our classification models.  The data is also split and named appropriately below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df = pd.read_csv('../data/Emotion(happy).csv')\n",
    "sad_df = pd.read_csv('../data/Emotion(sad).csv.zip', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([happy_df, sad_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df.drop('sentiment', axis = 1)\n",
    "y = full_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X['content'], y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1287    ['You Hurt Me But I Still Love You.', 'True Lo...\n",
       "1112    Sorry isn’t always enough. Sometimes you actua...\n",
       "823     Sometimes two people have to fall apart to rea...\n",
       "651     True love isn’t love at first sight but love a...\n",
       "1101    i am scared of getting too close to anyone bec...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e18b1dc3c81b6e5643a623246e6f713",
     "grade": false,
     "grade_id": "cell-1af9c3aaf69f904f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Using the `CountVectorizer`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "To create a bag of words representation of your text data, below create an instance of the `CountVectorizer` with default settings as `cvect`. \n",
    "\n",
    "Next, use the `fit_transform` function on `cvect` to transform the training data `X_train` and assign the transformed version of the text to `dtm`.  \n",
    "\n",
    "\n",
    "Hint: Make sure to transform X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf6c9720d2a66f85206ba601dc28737f",
     "grade": false,
     "grade_id": "cell-993194297edf95fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_0</th>\n",
       "      <th>100</th>\n",
       "      <th>123whatsappstatus</th>\n",
       "      <th>204</th>\n",
       "      <th>30</th>\n",
       "      <th>404</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>55</th>\n",
       "      <th>805</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yous</th>\n",
       "      <th>yuh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1832 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_0  100  123whatsappstatus  204  30  404  44  45  55  805  ...  yes  \\\n",
       "0    0    0                  0    0   0    0   0   0   0    0  ...    2   \n",
       "1    0    0                  0    0   0    0   0   0   0    0  ...    0   \n",
       "2    0    0                  0    0   0    0   0   0   0    0  ...    0   \n",
       "3    0    0                  0    0   0    0   0   0   0    0  ...    0   \n",
       "4    0    0                  0    0   0    0   0   0   0    0  ...    0   \n",
       "\n",
       "   yesterday  yet  you  young  your  yours  yourself  yous  yuh  \n",
       "0          0    1  112      0    13      0         2     0    0  \n",
       "1          0    0    1      0     0      0         0     0    0  \n",
       "2          0    0    0      0     0      0         0     0    0  \n",
       "3          0    0    0      0     0      0         0     0    0  \n",
       "4          0    0    0      0     0      0         0     0    0  \n",
       "\n",
       "[5 rows x 1832 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "cvect = CountVectorizer()\n",
    "dtm = cvect.fit_transform(X_train)\n",
    "\n",
    "### ANSWER CHECK\n",
    "pd.DataFrame(dtm.toarray(), columns = cvect.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "629b418305461e1aba62fe3e311b4c36",
     "grade": true,
     "grade_id": "cell-c04bf752bca2c8b0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19c1ac28b46db344d5a72a8731f0f3c1",
     "grade": false,
     "grade_id": "cell-748f6d75238662a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Limiting words with the `CountVectorizer`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Now, to remove stopwords from the text before vectorizing create a new instance of the `CountVectorizer` with argument `stop_words = 'english'`. Assign this to the variable `cvect2`.\n",
    "\n",
    "Next, use the `fit_transform` function on `cvect2` to transform the training data `X_train` and assign the transformed version of the text to `X_train_vect_2`.  \n",
    "\n",
    "Finally, transform the test data `X_test` as `X_test_vect_2` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e7a176a89a462c375166de7afe0567f",
     "grade": false,
     "grade_id": "cell-3774a2265d6e5e27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1007x1622 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 41589 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "cvect2 = CountVectorizer(stop_words='english')\n",
    "X_train_vect_2 = cvect2.fit_transform(X_train)\n",
    "X_test_vect_2 = cvect2.transform(X_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "X_train_vect_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8caad377dc67de4f76fcf0c3a00ed6ec",
     "grade": true,
     "grade_id": "cell-e51bed3fb28e4961",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cc4d75a8e360909607076664d588470",
     "grade": false,
     "grade_id": "cell-08908731ede92487",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 3\n",
    "\n",
    "#### Limiting words with stopwords and higher counts\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "\n",
    "Now, to remove stopwords from the text before vectorizing with 300 features create a new instance of the `CountVectorizer` with arguments `stop_words = 'english'` and `max_features = 300`. Assign this to the variable `cvect3`.\n",
    "\n",
    "Next, use the `fit_transform` function on `cvect3` to transform the training data `X_train` and assign the transformed version of the text to `X_train_vect_3`.  \n",
    "\n",
    "Finally, transform the test data `X_test` as `X_test_vect_3` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71d81b27ffc8e89a34b16cfa48c2f805",
     "grade": false,
     "grade_id": "cell-fc155b6ae942f747",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1007x300 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 33225 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### GRADED\n",
    "cvect3 = CountVectorizer(stop_words='english', max_features=300)\n",
    "X_train_vect_3 = cvect3.fit_transform(X_train)\n",
    "X_test_vect_3 = cvect3.transform(X_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "X_train_vect_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e37eb317fc6df865236fe5f83af4310",
     "grade": true,
     "grade_id": "cell-b1e8621d879a2aa7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0a0a1fdd242a98464054c8229bf1834",
     "grade": false,
     "grade_id": "cell-52dbe3ec03ade066",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Using the text with `LogisticRegression`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Create a `Pipeline` object named `vect_pipe_1` below that has steps named `cvect` and `lgr`, using both a default `CountVectorizer` transformer and `LogisticRegression` estimator. \n",
    "\n",
    "Fit this pipeline on the training data `X_train` and `y_train`.\n",
    "\n",
    "Finally, use the function `score` to evaluate it on the test set `X_test` and `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b1d5888129599771a348635820333c",
     "grade": false,
     "grade_id": "cell-0ced72c8a300928f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8273809523809523\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "vect_pipe_1 = Pipeline([\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('lgr', LogisticRegression())\n",
    "])\n",
    "\n",
    "vect_pipe_1.fit(X_train, y_train)\n",
    "\n",
    "test_acc = vect_pipe_1.score(X_test, y_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "vect_pipe_1.named_steps\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a42556c5f85b26a79eaabdf632cdc0b1",
     "grade": true,
     "grade_id": "cell-153fc31becfdf95e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e216cff718f322e7de49c6aacc692d0",
     "grade": false,
     "grade_id": "cell-67c7fd85b923ac68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Pipeline and Grid Search\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Initialize a `GridSearchCV` object with the pipeline `vect_pipe_1` and parameter grid `params` given below. Assign this result to the variable `grid`.\n",
    "\n",
    "Fit the `grid` object on training data `X_train` and `y_train`.\n",
    "\n",
    "Finaly, use the function `score` to evaluate it on the test set `X_test` and `y_test`. Assign the result to `test_acc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'cvect__max_features': [100, 500, 1000, 2000],\n",
    "         'cvect__stop_words': ['english', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5c26d73d370648dd664d3dfddabdac9",
     "grade": false,
     "grade_id": "cell-e57872e309a8659f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8273809523809523\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "grid = GridSearchCV(estimator=vect_pipe_1, param_grid=params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "\n",
    "### ANSWER CHECK\n",
    "grid.best_params_\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a6254865e16e976411d8a40535cca48",
     "grade": true,
     "grade_id": "cell-9b5e5e18bd2bee37",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
